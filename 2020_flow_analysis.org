# My R script for flow cytometry analysis in R in a literate org doc

[[stopping_point]]

* TODO Issues [14%]

    - [X] remove any 'adjust = ' from density plots
      + test w/ no adjust syntax in plot code

    - [ ] finish formatting so it can run from MSI
      + might also make a script to move stuff to and from MSI
        - stick the R CMD batch in the middle, then delete everything when finished
        - could rsync the dirs too to get all the results, none of the fcs

    - [ ] re-write code for replicate plots
      + ea. replicate = separate color
      + mean trace = black

    - [ ] re-do gating so that we take +/- 1.5 SDs of FSC and SSC instead of curv gate

    - [ ] look into Christian's approach for fsc correction 

    - [ ] more sensible legends 
      + stop using "_"

    - [ ] increase lwd on density plots
      + maybe 1.5-2.5x

#+NAME: christian_fsc_correction 
#+BEGIN_SRC R

subdataMC<-subdataMC[subdataMC$FSC.A>0 & subdataMC$SSC.A>0 & subdataMC$mCherry.A>0 & subdataMC$GFP.A>0,]
subdataMC<-subdataMC[log(subdataMC$GFP.A)>4.8,]
#plot(log(subdataMC$GFP.A),log(subdataMC$mCherry.A))test<-loess(log(subdataMC$mCherry.A)~subdataMC$FSC.A)
subdataMC$mCHc<-unlist(test$residuals)+mean(log(subdataMC$mCherry.A))
test2<-loess(log(subdataMC$GFP.A)~subdataMC$FSC.A)
subdataMC$GFPc<-unlist(test2$residuals)+mean(log(subdataMC$GFP.A))

#+END_SRC

* Misc. Notes
Remember that you can use radio buttons in the code as a means of generating
links in the written portion of this document:

[[goes_here][this_link]]

<<goes_here>>

* Flow Analysis Overview
My approach to flow cytometry data analysis in R is to collect 10-50,000 cells
of multiple biological replicates of the same strain/reporter and compare these
across strains/reporters for a single flow session.  At present, I typically
fill a 96-well plate with 7-8 biological replicates of each strain/reporter of
interest and collect 10,000 cells from each well.  Collecting more cells per
well (e.g., 50,000) does not seem to change the results appreciably and for
several of the downstream analyses in this document, the mean of these 10,000
cells is used as a single data point, making collecting additional cells
unnecessary.  

* [[Required_Packages]]
The analysis requires several packages from both regular R package repositories
and Bioconductor.  Setting up the script so that the packages are installed if
they're not available has proven challenging.  I've attempted to do this using
MSI as a test of whether the scripts are working.  Access to R through MSI is
illustrated in the following script: 

#+NAME: MSI_login_R_load
#+BEGIN_SRC bash
## -----
## login to MSI/mesabi
ssh mahlon@login.msi.umn.edu
ssh mesabi

## albert lab compute node
ssh cn5711


## -----
## determine which R versions are available
module avail R

## load the latest version
module load R/3.6.0
## now calling R should load the above version (3.6.0)
R
#+END_SRC

Installing packages, in particular Bioconductor packages, has been challenging
using MSI.  One of the issues has been error messages about directory locking
during package installation.  A solution to this issue is described here:
[[https://stackoverflow.com/questions/14382209/r-install-packages-returns-failed-to-create-lock-directory][SO_link]]

The solution boils down to setting an option for the install to [['--no-lock']] as
shown in the link.  This seems to work with both 'install.packages' and
'BiocManager::install'.

* [[color_setup]]
#+DATE: 2020.04.21
My color setup uses the same color for each strain background.  So, for example,
the BY strains always use the same blue color, the RM strains always use the
same magenta color, etc...  I used to use a setup wherein the number of colors
was set programmatically (using the 'rainbow' function) based on how many
strains were present.  The issue with this approach is that the strains never
had the same colors across plots/flow runs and I found myself changing the
strain colors by hand in inkscape, which is not desirable.

My current approach Using the same color for each strain background also has
limitations.  Namely, you can't plot multiple reporters in the same strain
background in the same plot.  For now, I'm not concerned about this issue, as
I'm typically plotting one reporter per plot.  Should the need arise to plot
multiple reporters and strain backgrounds in a single plot, varying the line
type is an easy solution to this issue.

Developing an approach to set the strain colors was not straightforward.  The
current approach seems to work, but is not especially elegant or efficiently
coded.  The idea behind the approach is to create association lists of strain
background and color.  Then, the strain list (those strains that were analyzed
for a particular run) is used to filter the strain-color association list.  The
result is a list of colors that is the same length as the strain list.  Getting
there is not particularly straightforward.  I use the following steps:

    - [1] 'sapply' the strain-color regular expression as a pattern for 'grepl'
      and use the strain names as the vector to match against.  The result of
      this operation is an n*6 table, where n is the number of strains.  

    - [2] 'sapply' each column of the n*6 table.  I collapse across the rows in
      each column to a single, logical value.  Basically, if a strain name
      matched, keep it, if it didn't, discard it.  The result is a logical
      vector the same length as the color list

    - [3] I then unlist the color list and subset on the logical vector above.
      This gives a color vector that is the same length and order as the strain
      list and can be used in subsequent plotting operations. 

* [[Reading_FCS_Files]]
I've attempted to automate as much of the analysis of flow data as possible.
The user needs to input information in certain places, however, and I've marked
these places with the following placeholder:

##############
## USER INPUT:
##############

My general approach to analyzing the data after loading required packages is as
follows:

    - [1] set the working directory to the location of the data

    - [2] build a directory structure for data, scripts, and results files: 
          + directories for: 
            - fcs files
            - results
            - tables
            - scripts

    - [3] read .fcs files using regex for strains
          + regex is: 
            - strain
            - reporter
            - replicate
              > e.g., BY_rpn4_TFT_004.fcs

    - [4] provide descriptive strain names for the plots
          + e.g., "no reporter", "BY rpn4_sfGFP_TFT", etc...

Once I've finished these steps, I build a list whose elements are the regex I'll
use to read fcs files for individual strains.  I use lapply to find all the
files that match all the strain names using the 'read.flowSet' function with a
pattern option.  The result is a list of ungated flowsets named 'all.strains'.
The length of all.strains is equal to the number of strains analyzed.  So, if I
had the following strain regex list:

no.reporter   <- ".*untagged.*fcs"
by.rpn4.tft   <- "BY.*rpn4.*.fcs"
rm.rpn4.tft   <- "RM.*rpn4.*.fcs"
rpn4.rpn4.tft <- "rpn4.*rpn4.*.fcs"

'all.strains' would be of length 4.  To access the individual replicates that
make up each list element of all.strains, I would use syntax like:

all.strains\[[2]\]\[[4]\], which would access the fourth replicate of
'by.rpn4.tft' above.  

In flowcore parlance, a 'flowSet' is simply a list of 'flowFrames', where
flowFrames are individual .fcs files.  


-----
To ensure the regex I set up work as intended, I also write the replicate
groupings of each flowSet in 'all.strains' to a table.   I recently (2020.03.05)
re-did the function that groups the strains to write a more R/UNIX friendly
table that shows which group each fcs file was assigned to and which regex was
used to place it in a group.  The table is easily viewed using the following:

column -t -s "," ./strain_replicate_groupings.txt

* [[Transformation_and_Gating]]
I apply two transformations to each flowframe initially: 

    - [1] truncation transformation
          + this converts 0's to 1's in the fluor channels
          + this allows us to log10 transform the fluors
            - i.e., log10(0) = -inf

    - [2] ratio transformation
          + this gives us the TFT and PSV ratios
            - TFT ratio = log2(RFP/GFP)
            - PSV ratio = log2(GFP/RFP)

I use lapply in combination with its flowCore equivalent, 'fsApply'.  The
result is that we apply the transform function to each flowframe via 'fsApply'
via applying the function to each element of 'all.set' through 'lapply'.  i.e.,
lapply fsApply using all.set.  

* Flow Analysis Source Code
#+BEGIN_SRC R
## -----
## <<Required_Packages>> 
## check for Bioconductor and install if not available 
ifelse(!requireNamespace("BiocManager", quietly = TRUE),
       install.packages("BiocManager",
                        dependencies = TRUE,
                        repos = "http://cran.wustl.edu/",
                        quiet = TRUE),
       paste0("Bioconductor available"))
require("BiocManager")

## requireNamespace checks whether a package is available and loads if it is
## the return value is logical and the function throws an error if not available 
## if(!requireNamespace("DNAcopy")) paste0("package not available")
## check that the output of requireNamespace is truly logical:
## requireNamespace("dygraphs") == requireNamespace("lattice")     ## TRUE
## requireNamespace("dygraphs") == requireNamespace("fakepackage") ## FALSE
## ifelse(!requireNamespace("fakepackage"),
##        paste0("no such package"),
##        paste0("there is a package"))


## -----
## load packages or install if not available
## have to split these out by bioconductor vs. non-bioconductor
## non-bioconductor
package_installer <- function(x){
    if(!requireNamespace(x, quietly = TRUE))
        install.packages(x, dependencies = TRUE,
                         repos = "http://cran.wustl.edu/",
                         quiet = TRUE, INSTALL_opts = '--no-lock')}
packages <- c("colorspace", "lattice", "ggvis", "dygraphs")
sapply(X = packages, FUN = package_installer)
sapply(X = packages, FUN = require, character.only = TRUE)


## -----
## bioconductor
bioc_package_installer <- function(x){if(!requireNamespace(x))
                                          BiocManager::install(x, INSTALL_opts = '--no-lock')}
bioc_packages <-  c("flowCore", "flowViz", "flowUtils", "flowStats", "flowFP", "geneplotter", "ggcyto")
sapply(X = bioc_packages, FUN = bioc_package_installer)
sapply(X = bioc_packages, FUN = require, character.only = TRUE)


## -----
## required for merging flowsets into a single flowframe 
source(file = "https://raw.githubusercontent.com/mac230/flow_scripts/master/set2frame.R")


##-----
## <<Reading_FCS_Files>>
## user-specified options - these will change for each analysis depending on strains/reporters
##############
## USER INPUT:
##############
## no trailing '/' at the end!
base.dir       <- "~/data/flow/2020.03.14_new_gate_testing"
setwd(base.dir)
needed.dirs <- c("/fcs", "/results", "/tables")
dir.maker <- function(x){if(!dir.exists(paths = paste0(base.dir, x)))
                             dir.create(path = paste0(base.dir, x))}
sapply(X = needed.dirs, FUN = dir.maker)
work.dir       <- paste0(base.dir, "/fcs")
results.dir    <- paste0(base.dir, "/results")
tables.dir     <- paste0(base.dir, "/tables")


##-----
## [x]
## now set regex for getting flowsets of the different strains
## generally, should name fcs files as follows:
## strain    - by, rm, rpn4, rpn10
## reporter  - PSV, TFT, untagged
## replicate - 001, 002, etc... per strain
##############
## USER INPUT:
##############
no.reporter   <- ".*untagged.*fcs"
by.thr.tft    <- "BY.*Thr.*.fcs"
rm.thr.tft    <- "RM.*Thr.*.fcs"
doa10.thr.tft <- "doa10.*Thr.*.fcs"


##############
## USER INPUT:
##############
## for later use in plots
strain.names <- c("no reporter", "BY Thr TFT", "RM Thr TFT", "doa10 Thr TFT")


##-----
## [x]
## bind all regex to a list and use the list to read files
## the result here is a list of ungated flowSets
## each flowset has 'n' tubes (flowframes), where n is the number of replicates
## access a single flowFrame/tube w/ .e.g. "all.set[[1]][[1]]", which would be strain 1, tube 1
##############
## USER INPUT:
##############
setwd(work.dir)
all.strains <- list(no.reporter,  
                    by.thr.tft,  
                    rm.thr.tft,  
                    doa10.thr.tft)

all.set     <- lapply(all.strains, function(x){read.flowSet(files = NULL, path = ".", pattern = x, alter.names = T, min.limit = 1)})
## str(all.set[[1]]@phenoData@data$name)

##################
## END USER INPUT:
##################


## -----
## <<color_setup>>
## linking colors to strain names in R
## I think I should be able to make something
## akin to an lisp association list where
## there is a strain name and associated color
col.untagged <- c(color = gray(0.7),   name = "no reporter")
col.by       <- c(color = "#7A9BCCFF", name = ".*BY.*")
col.rm       <- c(color = "#CC7AAAFF", name = ".*RM.*")
col.rpn4     <- c(color = "#CCAB7AFF", name = ".*rpn4.*")
col.ubr1     <- c(color = "#88CCBBFF", name = ".*ubr1.*")
col.doa10    <- c(color = "#A3CC7AFF", name = ".*doa10.*")
cols.list    <- list(col.untagged, col.by, col.rm, col.rpn4, col.ubr1, col.doa10)

col.out <- sapply(X = cols.list, FUN = function(x){
                      grepl(pattern = x["name"], x = strain.names )
                  })
col.out <- as.logical(unlist(sapply(1:ncol(col.out), FUN = function(x){
                      max(col.out[, x])
                      })))
all.cols <- unlist(sapply(X = cols.list[col.out], FUN = function(x){identity(x["color"])}))

## output a dummmy plot to assess strain/color mapping
setwd(results.dir)
pdf(file = "color_mapping.pdf", height = 7, width = 7, bg = "transparent")
barplot(rep(4, length(strain.names)), col = all.cols, ylim = c(0, 5.5))
box()
legend(x = "topleft", legend = strain.names, lty = 1, lwd = 7.5, col = all.cols, bg = "white")
legend(x = "topright", y = NA,
       legend = unlist(lapply(X = cols.list, FUN = function(x){identity(x)["name"]})),
       col = unlist(lapply(X = cols.list, FUN = function(x){identity(x)["color"]})),
       lty = 1, lwd = 7.5,  bg = "white")
dev.off()


##-----
## [x]
## write strain/replicate groupings to a table for inspection
## view w/ 'column -t -s "," ./tables/strain_replicate_groupings.txt'
setwd(tables.dir)
cat("File, Group, Strain", "\n", file = "strain_replicate_groupings.txt", append = F)
strain.group    <- as.list(seq(from = 1, to = length(all.set), by = 1))
replicates.out  <- unlist(lapply(1:length(all.set),
                                 function(x)
                                 {paste0(all.set[[x]]@phenoData@data$name, ", ",
                                         strain.group[[x]], ", ", strain.names[[x]])}))
replicate.table <- function(x){cat(c(x, "\n"), file = "strain_replicate_groupings.txt", append = T, sep = ", ")}
sapply(X = replicates.out, FUN = replicate.table)


##-----
## <<Transformation_and_Gating>>
## use the transform function to get the TFT/PSV parameters we want
## start by converting 0's in fluors to 1's via truncate transform
trunc.trans   <- truncateTransform("Convert 0's to 1's.", a = 1)
trunc.fluors  <- function(x){
    transform(x,
              `eGFP.A` = trunc.trans(`eGFP.A`),
              `mCherry.A` = trunc.trans(`mCherry.A`))}
all.set <- lapply(all.set, fsApply, trunc.fluors)

PSV.TFT.transform <- function(x){
    transform(x,
              `log_GFP` = log10(`eGFP.A`),
              `log_RFP` = log10(`mCherry.A`),
              `TFT_ratio` = log(`mCherry.A`/`eGFP.A`, base = 2),
              `PSV_ratio` = log(`eGFP.A`/`mCherry.A`, base = 2),
              ## 'no log' TFT ratio
              `nl_TFT_ratio` = `mCherry.A`/`eGFP.A`)}
all.set <- lapply(all.set, fsApply, PSV.TFT.transform)


##-----
## [x]
## get the total number of cells for each flowFrame
## nrow is passed as an optional arg to fsApply here
total.cells <- lapply(all.set, fsApply, nrow)


##-----
## [x]
## 02.27.2019 try this w/ curv2Filter w/ a big bandwidth setting to grab the
## main cloud of cells we take only cells in 'area 1' (the gate), not 'rest'
## (the cells outside the gate)
initial.split <- function(x) {
    split(x, f = curv2Filter(x = "FSC.A", y = "SSC.A", bwFac = 7, gridsize = c(250,250)),
          population = "area 1", flowSet = TRUE, codeflowSet = TRUE)
}
## this object is a list of flowsets of the cells in the initial gate (area 1)
## each flowset in this list contains only 1 flowFrame
initial.split.all <- lapply(all.set, fsApply, initial.split)


##-----
## [x]
## plot the cells w/ their associated filter gate
setwd(results.dir)
dir.create(path = paste0(results.dir, "/cell_gate_plots"))
cell.gate.dir <- paste0(results.dir, "/cell_gate_plots")
setwd(cell.gate.dir)

xy.initial.pdf <- function(x){
    pdf(file = paste0("initial_", x@description$"TUBE NAME", ".pdf"), height = 7, width = 7)
    print(xyplot(`SSC.A` ~ `FSC.A`, data = x,
                 filter = curv2Filter(x = "FSC.A", y = "SSC.A", bwFac = 10, gridsize = c(250,250)),
                 smooth = F))
    dev.off()
}
lapply(all.set, fsApply, xy.initial.pdf)


##-----
## [x] - 2020.04.19 - no longer using due to fsc gating approach below 
## plot the results of the pre-filter plus curv2Filter gating
## start by undoing the complicated list structure the filter operation creates
## this yields a list of flowSets
## initial.curv.split <- unlist(initial.split.all)
##setwd(cell.gate.dir)
##xy.initial.curv.pdf <- function(x) {
##    pdf(file = paste0("curv_", x@description$"TUBE NAME", "_.pdf"), height = 7, width = 7)
##    print(xyplot(`SSC.A` ~ `FSC.A`, data = x,
##                 filter = curv2Filter(x = "FSC.A", y = "SSC.A", bwFac = 2, gridsize = c(250,250)),
##                 smooth = F))
##    dev.off()
##}
##lapply(initial.curv.split, fsApply, xy.initial.curv.pdf)


## -----
## a function to gate the cells to include only haploids.
## we identify these as a sharp peak in the lower end of
## the fsc density plot.  I take 10% above and below the
## max density value 
fsc.gate.generator <- function(x){
    fsc.dens  <- density(exprs(x[, 1]))
    ## return the index of the maximum y value of the density estimate
    fsc.max   <- fsc.dens[[1]][which.max(fsc.dens[[2]])]
    fsc.upper <- (fsc.max * 0.10) + fsc.max
    fsc.lower <- fsc.max - (fsc.max * 0.10)
    fsc.gate  <- c(fsc.lower, fsc.upper)
}

curv.split <- function(x){
    split(x, f = rectangleGate("FSC.A" = fsc.gate.generator(x)),
          population = "defaultRectangleGate+",
          flowSet = T, codeflowSet = T)}
curv.set <- lapply(all.set, fsApply, curv.split)


##-----
## [x]
## plot the results of the pre-filter plus curv2Filter gating
## start by undoing the complicated list structure the filter operation creates
## this yields a list of flowSets
setwd(cell.gate.dir)
xy.fsc.curv.pdf <- function(x) {
    pdf(file = paste0("curv_", x@description$"TUBE NAME", "_.pdf"), height = 7, width = 7)
    print(xyplot(`SSC.A` ~ `FSC.A`, data = x, main = x@description$"TUBE NAME",
                 filter = rectangleGate("FSC.A" = fsc.gate.generator(x)),
                 smooth = F))
    dev.off()
lapply(all.set, fsApply, xy.fsc.curv.pdf)

fsc.density.curv.pdf <- function(x){
    pdf(file = paste0("fsc_density_", x@description$"TUBE NAME", "_.pdf"), height = 7, width = 7)
    plot(density(exprs(x[, 1])), xlab = colnames(exprs(x))[1], main = x@description$"TUBE NAME")
    abline(v = fsc.gate.generator(x), col = gray(0.4), lty = 3, lwd = 2)
    dev.off()
}
lapply(all.set, fsApply, fsc.density.curv.pdf)


## NOT WORKING - SEEMS THESE ARE NOT GETTING CODED AS FLOWFRAMES/SETS
gated.xy.fsc.curv.pdf <- function(x){
    pdf(file = paste0("xy_sub_population_curv_", x@description$"TUBE NAME", "_.pdf"), height = 7, width = 7)
    print(xyplot(`SSC.A` ~ `FSC.A`, data = x, main = x@description$"TUBE NAME",
                 filter = rectangleGate("FSC.A" = fsc.gate.generator(x)),
                 smooth = F))
    dev.off()
}
lapply(curv.set, function(x){lapply(x, fsApply, gated.xy.fsc.curv.pdf)})

## so, what do the final sets needs to look like as data structures? 

<<stopping_point>>

#+END_SRC
